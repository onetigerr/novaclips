# Создание фейслес роликов для YouTube.

### Ниша.  AI & Tech “how it works”

### Подниши, которые отлично ложатся на ген‑визуал:

- “LLMs explained”: токены, контекстное окно, эмбеддинги, RAG, tool use, агенты, evals.

- “Workflow automation concepts”: очереди, ретраи, идемпотентность, rate limiting, circuit breaker, event-driven, DAG’и.

- “AI myths”: что модель «знает/не знает», почему уверенно ошибается, как читать бенчмарки.

## <u>LLMs explained</u>: рекомендуемая серия из 6 роликов (10–15 минут каждый)

### Ролик 1 — Токены и контекстное окно

- Главная идея: контекст — это **вход + выход** в токенах, и это реальное вычислительное ограничение.[[dev](https://dev.to/qvfagundes/temperature-tokens-and-context-windows-the-three-pillars-of-llm-control-34jg)]​

- Объяснить, почему “добавим ещё текста” дорого: внимание масштабируется квадратично O(n2), поэтому удвоение контекста может сильно увеличивать вычисления.[[dev](https://dev.to/qvfagundes/temperature-tokens-and-context-windows-the-three-pillars-of-llm-control-34jg)]​

- Визуалы: “лента токенов”, счётчик токенов, “окно” как рамка, которая двигается; мини-кейс “почему модель забывает начало диалога”.

### Ролик 2 — Эмбеддинги и векторный поиск (без матана)

- Что такое эмбеддинг: перевод текста в вектор, чтобы сравнивать “похожесть по смыслу” (интуитивно: близко/далеко в пространстве).

- Почему качество retrieval зависит от эмбеддингов и чанкинга: от этого зависит, какие куски попадут в контекст для ответа.[[promptingguide](https://www.promptingguide.ai/research/rag)]​

- Визуалы: “карта смыслов” (точки-кластеры), запрос как стрелка, top‑k как подсветка ближайших точек.

### Ролик 3 — RAG: как “добавить память” без расширения контекста

- Канонический пайплайн: разбили базу знаний на чанки → построили эмбеддинги → нашли релевантные чанки → **вставили их в контекст** → сгенерировали ответ.[[blog.epsilla](https://blog.epsilla.com/how-retrieval-augmented-generation-rag-overcomes-llm-limitations-an-end-to-end-guide-49da1a9a400a)]​

- Смысл RAG как способа “не тащить всё в prompt”: храните знания снаружи, достаёте только нужное и кладёте в окно контекста.[[dev](https://dev.to/qvfagundes/temperature-tokens-and-context-windows-the-three-pillars-of-llm-control-34jg)]​

- Визуалы: конвейер из 5 блоков, “библиотека” (vector DB), “инъекция контекста” как вставка карточек в prompt.

### Ролик 4 — Tool use / function calling: как LLM начинает “делать”

- Развести понятия: “модель говорит” vs “модель вызывает инструмент”, и инструмент возвращает наблюдаемый результат (поиск, калькулятор, база, код).

- Показать на мини-сценарии: “узнай статус заказа” (tool = CRM), “посчитай” (tool = калькулятор), “найди в документации” (tool = retrieval).

- Визуалы: схема “LLM ↔ инструменты”, лог вызовов, “контракт” вход/выход инструмента.

### Ролик 5 — Агенты: когда tool use превращается в цикл

- Объяснить “агентность” как: план → действие (tool) → наблюдение → следующий шаг, пока не решит задачу.

- Показать, что RAG легко упаковывается как инструмент агента (инструмент “retrieve_context”), и агент использует его перед ответом.[[docs.langchain](https://docs.langchain.com/oss/python/langchain/rag)]​

- Визуалы: диаграмма цикла, “память состояния”, трассировка шагов (step 1/2/3).

### Ролик 6 — Evals: как измерять качество (и не спорить “кажется лучше”)

- Зачем: без evals Вы не поймёте, улучшили ли prompt/RAG/агента, или просто “повезло на примерах”.

- Что мерить: (1) качество ответа, (2) качество retrieval, (3) стоимость/токены/латентность, (4) устойчивость к “плохим” запросам.

- Практический якорь: есть подходы/инструменты, которые учат собирать датасеты и прогонять оценки для RAG-приложений.[[docs.langchain](https://docs.langchain.com/langsmith/evaluate-rag-tutorial)]​
